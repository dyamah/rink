概要（暫定版 0.2）

  rink プロジェクトはIWPT2003で提案した英語の決定性上昇型依存構造解析({{Y & M IWPT03}})のJava実装です。

動作環境

  * JRE 1.6以降

必要なモジュール

  * rinkモジュール本体：${project.name}-${project.version}.jar　

  動作には以下２つのモジュールが必要です。
  詳細は{{{./dependencies.html}依存関係}}を参照してください。

  *{{{http://www.csie.ntu.edu.tw/~cjlin/libsvm/} LIBSVM}}:  SVMライブラリ。SVMで学習をする場合に必要

  *{{{http://commons.apache.org/cli/} commons-cli}}:  コマンドライン解析ライブラリ


入出力データ形式

   解析対象文の入出力データは、{{CoNLL-X}} の{{{http://ilk.uvt.nl/conll/index.html#dataformat}書式}}と同じとします。

コーパスについて

  研究でよく利用する英語の依存構造解析済みコーパスは、Penn Treebank コーパスの句構造を依存構造に変換したものです。
  ここでは公開されているツールの情報を簡単にまとめておきます。

  [[1]] {{Penn2Malt}}

        Nivre のJava実装です。現在開発はfixしており、過去の論文の結果を再現するためのツールという位置づけのようです。
        後継は下のpennconverterです。

  [[2]] {{pennconverter}}

        ここではPenn Treebank コーパスにDavid Vadasの{{{http://sydney.edu.au/engineering/it/~dvadas1/?Noun_Phrases} 名詞句タグ付けの修正パッチ}}
        をあてることを強く奨めています。

  []

  Penn2Malt と pennconverter は、標準の主辞規則が大きく異なります。したがって出力する依存木は Penn2Malt とは異なります。
  後述する実験では過去の研究との比較のため Penn2Malt と同じ出力をCoNLL形式に変換したものを利用しています。

使用方法

* 前提

  * $train.txt: CoNLL-X書式の依存構造解析済みテキスト

  * $model: 学習モデル。

  * $test.txt:　CoNLL-X書式のテストデータ

  * ${project.name}-${project.version}.jar: rinkモジュール jarファイル。

  * $libsvm.jar: libsvm のjar ファイル。　使用しているバージョンに読み替えてください。

  * $commons-cli.jar: コマンドラインパーザのjar ファイル。使用しているバージョンに読み替えてください。

* LIBSVMを利用した学習方法

  IWPT2003 と同じ設定で学習モデルを作成

  * 学習アルゴリズム：SVM

  * Kernel 関数： 2次の多項式 Kernel

  * 素性：IWPT2003での最良結果と同等

  * 訓練データの分割：依存構造を構築するかどうかを判定する２つの単語のうち左の単語の品詞でグループ化

+------------------------------------------------------------------------------------------------------------------------------------------------+
% java -Xmx 1024m -cp ${project.name}-${project.version}.jar:$libsvm.jar:$commons-cli.jar jp.gr.java_conf.dyama.rink.tools.DependencyLearner -i $train.txt -o $model -l IWPT2003
+------------------------------------------------------------------------------------------------------------------------------------------------+

* 学習したモデルを利用した解析方法

+------------------------------------------------------------------------------------------------------------------------------------------------+
% java -Xmx 512m -cp ${project.name}-${project.version}.jar:$commons-cli.jar jp.gr.java_conf.dyama.rink.tools.DependencyParser -i $test.txt -m $model -v
+------------------------------------------------------------------------------------------------------------------------------------------------+

  上記コマンドで標準出力にCoNLL-X形式の解析結果を出力します。
  また標準エラー出力に実行時間や使用メモリについての情報が出力されます。

+------------------------------------------------------------------------------------------------------------------------------------------------+
loading time[s]       :	1.42
parsing time[s]       :	77.12
parsing speed[sent/s] :	31.3
Total Time [s]    :	78.57
Total Memory [MB] :	237.71
+------------------------------------------------------------------------------------------------------------------------------------------------+

性能調査

* 実験環境

  * CPU: 2.3Ghz Intel Core i7

  * RAM: 16GB 1600MHz DDR3

  * OS: Mac OS X 10.8.2

  * JRE: 1.6

+---------------------------------------------------------------+
#以下は java -version の結果
java version "1.7.0_09"
Java(TM) SE Runtime Environment (build 1.7.0_09-b05)
Java HotSpot(TM) 64-Bit Server VM (build 23.5-b02, mixed mode)
+---------------------------------------------------------------+

* データ

  Penn Treebank の標準データセット(訓練データ section 02 から 21、テストデータ section 23)を使用しました。
  品詞タグ付けは先行研究でもよく利用されている {{Ratnaparkhi EMNLP96}}の実装{{mxpost}}を利用。
  品詞タグ付けのモデルは{{mxpost}}に添付されていた標準のモデルを使用しました。

* 性能評価指標

  以下7つの指標で性能を評価します。

  [[1]] POS Accuracy: 品詞タグ付けの精度

  [[2]] Dependency Accuracy: Punctuation 以外の単語に対する依存木の親の正解率

  [[3]] Unlabeled Attachment Score (UAS): CoNLL-Xの精度評価ツール {{{http://ilk.uvt.nl/conll/software.html#eval} eval.pl}} にて算出したDependency Accuracy 相当のスコア

  [[4]] Complete rate: Punctuation 以外の単語について１文で親ノードがすべて正しかった文の比率。

  [[5]] Root Accuracy: 依存木の親の正解数

  [[6]] Speed : 1秒あたりの解析文数（CoNLL-X書式の入出力も含む）

  [[7]] Memory: 実行時のピークヒープメモリサイズ (MB)。

  []

  2. 3. の違いは評価から除外するPunctuation の定義の差です。2.では Punctuation はテストデータの正解品詞により、以下の4品詞のいずれかがタグ付された単語をPunctuationとしています。

    "," ".", ":", "''", "``"

  これは IWPT2003 投稿時と若干異なります。(IWPT2003 では単語の表記が"," ".", ":", "''", "``"のいずれかに該当するものをPunctuationとしていました）
  また 3.のpunctuationの定義は perl のunicode で定義されているものをそのまま利用しているようです。

* 結果：解析精度/速度/使用メモリ

  ここでは以下３つのモデルについて記載します。

  [[1]] IWPT2003: IWPT2003 に記載した精度。当時の実装を完全にビルドできていないので学習ツール、測定環境等は他２つとは異なります。
        また使用している品詞タグ付け器({{Nakagawa ACL02}}) や精度評価ツールも若干異なっているので、あくまで参考情報という位置づけです。
        (当時の測定環境は CPU: Pentium 4 3.0Ghz, OSはLinux)

  [[2]] SVMs: rink モジュールでIWPT2003最良モデルを再現したモデル。

  [[3]] MIRA: rinkモジュールに試験実装したMIRAによるモデル(SVMの代わりにMIRAによって解析アクションを学習、分類したもの）。素性はSVMと同一で 解析アクションを少しだけ拡張しています。

*-------------------+----------*-------*-------*
                    | IWPT2003 | SVMs  | MIRA
*-------------------+----------*-------*-------*
 POS Accuracy       | 0.971    | 0.968 | 0.968
*-------------------+----------*-------*-------*
 Dependency Accuracy| 0.903    | 0.896 | 0.840
*-------------------+----------*-------*-------*
 UAS                | ?????    | 0.896 | 0.839
*-------------------+----------*-------*-------*
 Complete rate      | 0.384    | 0.375 | 0.236
*-------------------+----------*-------*-------*
 Root Accuracy      | 0.916    | 0.910 | 0.815
*-------------------+----------*-------*-------*
 Speed (sent./sec)  | 0.732    | 31.6  | 1891.9
*-------------------+----------*-------*-------*
 Memory (MB)        | 300.0    | 235.3 | 104.9
*-------------------+----------*-------*-------*

  []

  IWPT2003 とそれを再現したrinkモジュールの SVMはほぼ同等の精度を達成しています。
  学習ツール、品詞タグ付け器、および精度評価ツールが若干異なることを考慮すれば、IWPT2003の解析を再現できている思われます。
  解析速度は2次の多項式カーネルを使った場合で少なくとも 数十倍程度は高速化できてきます。(当時が遅すぎたという話もありますが）
  より高速にするにはLinear Kernelを使ったモデルが考えられますが、今回の最良素性では学習に３日以上かかること、また解析速度も２倍程度しか速くならないことが事前調査でわかっています。

  一方学習方法をMIRAに変えた場合、学習時間(SVMが約1日に対して数時間)、解析速度も高速化できますが、精度が落ちます。
  ただし最近の先行研究{{Zhang & Nivre ACL11}}ではMIRAのような線形分類器とビームサーチを組み合わせて非常に高い精度(UAS で 0.926)に達しています。
  解析速度も 2GHz のCPUで 29 [sent./sec] 程度と記載されています。

今後の予定

  現在 0.1 alpha 版として必要最低限のテストは実施していますが、一部試験実装（変更の可能性が高い箇所）でテストが不十分な部分がまだあります。
  また先行研究 Zhang & Nivre ACL2011 にあるように、ビームサーチを使うことで精度を上げることが可能なので、同様の機能をrinkモジュールにも取り込みたいと考えています。

  2013/3末にリリース予定の version 1.0　では以下の機能変更を予定しています。

    * SVM 学習機能の無効化（研究比較用のためモデルのロード、解析機能は可能のままにします。）

    * MIRA による学習機能、解析機能の対応

    * ビームサーチによる冗長解析機能

  また品質向上のため可能な限り多くのテストを追加する予定です。

謝辞

  rink プロジェクトは{{{http://lr-www.pi.titech.ac.jp/wp/}東京工業大学精密工学研究所 奥村・高村研究室}}で研究員として在職中に立ち上げたプロジェクトです。
  短い間ではありましたが自由に研究開発を行うことができました。
  このような環境を提供してくださり、また数々のアドバイスをくださった奥村先生、高村さん、笹野さん、そして研究室の皆さんに心より感謝いたします。

  本当にありがとうございました。

参考文献、リンク

  * {Y & M IWPT03}: {{{http://cl.aist-nara.ac.jp/papers/2003/hiroya-y/IWPT-2003.pdf}Hiroyasu Yamada and Yuji Matsumoto, "Statistical Dependency Analysis with Support Vector Machines", IWPT2003}}

  * {CoNLL-X}: {{{http://www.clips.ua.ac.be/conll2006/proceedings.html}The Tenth Conference on Natural Language Learning (CoNLL-X) 2006}}

  * {Penn2Malt} : {{http://w3.msi.vxu.se/~nivre/research/Penn2Malt.html}}

  * {pennconverter} : {{http://nlp.cs.lth.se/software/treebank_converter/}}

  * {mxpost}:　{{ftp://ftp.cis.upenn.edu/pub/adwait/jmx/}}

  * {Nakagawa ACL02} : {{{http://acl.ldc.upenn.edu/P/P02/P02-1063.pdf} Tetsuji Nakagawa and Taku Kudo and Yuji Matsumoto, "Revision Learning and its Application to Part-of-Speech Tagging", ACL2002}}

  * {Ratnaparkhi EMNLP96}: {{{http://www.inf.ed.ac.uk/resources/nlp/local_doc/mxpost_doc.pdf}Adwait Ratnaparkhi, "A Maximum Entropy Model for Part-of-Speech Tagging", EMNLP1996}}

  * {Zhang & Nivre ACL11}: {{{http://aclweb.org/anthology-new/P/P11/P11-2033.pdf} Yue Zhang and Joakim Nivre, "Transition-based Dependency Parsing with Rich Non-local Features", ACL2011 }}