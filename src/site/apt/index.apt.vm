概要

  rink プロジェクトはIWPT2003で提案した英語の決定性上昇型依存構造解析({{Y & M IWPT03}})のJava実装です。
  学習パッケージの違いなどにより当時と完全に同一の出力結果にはなりませんが、本質的な部分（解析アルゴリズムや素性として考慮している情報）は同一です。
  現在はベータ版という位置づけで、比較研究・実験を目的としたモジュールになっていますが、今後いろいろと拡張していきたいと思っています。
  2003年当時のプロトタイプは Ruby と一部C++で実装していましたが、今回は完全なJava実装にし、高速化もしました（というか当時が遅すぎた）。
  一応単体テストや最低限の動作確認は行なっていますが、まだまだ不備も多い方とおもいます。なにかあればご指摘いただければとおもいます。

  以下簡単に使用方法について説明していきます。

動作環境

* Java 実行環境

  * JRE 1.7以降

* 必要なモジュール

  * rinkモジュール本体：{{{./releases/${project.name}-${project.version}-bin.tar.gz} ${project.name}-${project.version}-exec.jar }}　

  上記モジュールには動作に必要な以下２つの依存モジュールが同封されています。

    * {{{http://www.csie.ntu.edu.tw/~cjlin/libsvm/} LIBSVM}}:  SVMライブラリ。SVMで学習をする場合に必要

    * {{{http://commons.apache.org/cli/} commons-cli}}:  コマンドライン解析ライブラリ

  各依存モジュールのライセンス等の詳細は{{{./dependencies.html}ここ}}を参照してください。

入出力データ形式

  解析対象文の入出力データは、{{CoNLL-X}} の{{{http://ilk.uvt.nl/conll/index.html#dataformat}書式}}と同じとします。

* コーパスについて

  研究でよく利用する英語の依存構造解析済みコーパスは、Penn Treebank コーパスの句構造を依存構造に変換したものです。
  ここでは公開されている変換ツールの情報を簡単にまとめておきます。

  [[1]] {{Penn2Malt}}

        Nivre のJava実装です。現在開発はfixしており、過去の論文の結果を再現するためのツールという位置づけのようです。
        後継は下のpennconverterです。

  [[2]] {{pennconverter}}

        ここではPenn Treebank コーパスにDavid Vadasの{{{http://sydney.edu.au/engineering/it/~dvadas1/?Noun_Phrases} 名詞句タグ付けの修正パッチ}}
        をあてることを強く奨めています。

  []

  Penn2Malt と pennconverter は、標準の主辞規則が大きく異なります。したがって出力する依存木は Penn2Malt とは異なります。
  後述する実験では過去の研究との比較のため Penn2Malt と同じ出力をCoNLL形式に変換したものを利用しています。

使用方法

* 前提

  * $train.txt: CoNLL-X書式の依存構造解析済みテキスト

  * $model: 学習モデル。

  * $test.txt:　CoNLL-X書式のテストデータ


* LIBSVMを利用した学習方法

  以下のIWPT2003 と同じ設定で学習モデルを作成

  * 学習アルゴリズム：SVM

  * Kernel 関数： 2次の多項式 Kernel

  * 素性：IWPT2003での最良結果と同等

  * 訓練データの分割：依存構造を構築するかどうかを判定する２つの単語のうち左の単語の品詞でグループ化

+------------------------------------------------------------------------------------------------------------------------------------------------+
[使用方法]
% java -Xmx1024m -cp ${project.name}-${project.version}-exec.jar jp.gr.java_conf.dyama.rink.tools.DependencyLearner -i $train.txt -o $model -l IWPT2003
+------------------------------------------------------------------------------------------------------------------------------------------------+

  << 注意：Penn Treebankの標準データセット規模の学習を行うと最近のマシンでも学習に２日前後かかります。>>

* 学習したモデルを利用した解析方法

+------------------------------------------------------------------------------------------------------------------------------------------------+
% java -Xmx512m -jar ${project.name}-${project.version}-exec.jar -i $test.txt -m $model -v
+------------------------------------------------------------------------------------------------------------------------------------------------+

  上記コマンドで標準出力にCoNLL-X形式の解析結果を出力します。
  また標準エラー出力に以下のような実行時間や使用メモリについての情報が出力されます。

+------------------------------------------------------------------------------------------------------------------------------------------------+
loading time[s]       :	1.42
parsing time[s]       :	77.12
parsing speed[sent/s] :	31.3
Total Time [s]    :	78.57
Total Memory [MB] :	237.71
+------------------------------------------------------------------------------------------------------------------------------------------------+

精度・性能調査

* 実験環境

  * CPU: 2.3Ghz Intel Core i7

  * RAM: 16GB 1600MHz DDR3

  * OS: Mac OS X 10.8.2

  * JRE: 1.7

* データ

  Penn Treebank の標準データセット(訓練データ section 02 から 21、テストデータ section 23)を使用しました。
  品詞タグ付けは先行研究でもよく利用されている {{Ratnaparkhi EMNLP96}}の実装{{mxpost}}を利用。
  品詞タグ付けのモデルは{{mxpost}}に添付されていた標準のモデルを使用しました。

* 精度性能評価指標

  以下7つの指標で精度・性能を評価しています。

  [[1]] POS Accuracy: 品詞タグ付けの精度

  [[2]] Dependency Accuracy: Punctuation 以外の単語に対する依存木の親の正解率

  [[3]] Unlabeled Attachment Score (UAS): CoNLL-Xの精度評価ツール {{{http://ilk.uvt.nl/conll/software.html#eval} eval.pl}} にて算出したDependency Accuracy 相当のスコア

  [[4]] Complete rate: Punctuation 以外の単語について１文で親ノードがすべて正しかった文の比率。

  [[5]] Root Accuracy: 依存木のルート正解数

  [[6]] Speed : 1秒あたりの解析文数（CoNLL-X書式の入出力も含む）

  [[7]] Memory: 実行時のピークヒープメモリサイズ (MB)。

  []

  2. 3. の違いは評価から除外するPunctuation mark の定義の差です。2.では Punctuation はテストデータの正解品詞により、以下の4品詞のいずれかがタグ付された単語をPunctuation markとしています。

+----------------------------------+
    "," ".", ":", "''", "``"
+----------------------------------+

  これは IWPT2003 投稿時と若干異なります。(IWPT2003 では単語の表記が"," ".", ":", "''", "``"のいずれかに該当するものをPunctuation mark としていました）
  また 3.のpunctuationの定義は perl のunicode で定義されているものをそのまま利用しているようです。

* 結果：解析精度/速度/使用メモリ

  今回の実験では以下３つのモデルについて記載します。

  [[1]] IWPT2003: IWPT2003 に記載した精度。当時の実装を完全にビルドできていないので学習ツール、測定環境等は他２つとは異なります。
        また使用している品詞タグ付け器({{Nakagawa ACL02}}) や精度評価ツールも若干異なっているので、あくまで参考情報という位置づけです。
        (当時の測定環境は CPU: Pentium 4 3.0Ghz, OSはLinux)

  [[2]] SVMs: rink モジュールでIWPT2003最良モデルを再現したモデル。

  [[3]] MIRA: rinkモジュールに試験実装したMIRAによるモデル(SVMの代わりにMIRAによって解析アクションを学習、分類したもの）。素性はSVMと同一で 解析アクションを少しだけ拡張しています。

*-------------------+----------*-------*-------*
                    | IWPT2003 | SVMs  | MIRA
*-------------------+----------*-------*-------*
 POS Accuracy       | 0.971    | 0.968 | 0.968
*-------------------+----------*-------*-------*
 Dependency Accuracy| 0.903    | 0.896 | 0.840
*-------------------+----------*-------*-------*
 UAS                | ?????    | 0.896 | 0.839
*-------------------+----------*-------*-------*
 Complete rate      | 0.384    | 0.375 | 0.236
*-------------------+----------*-------*-------*
 Root Accuracy      | 0.916    | 0.910 | 0.815
*-------------------+----------*-------*-------*
 Speed (sent./sec)  | 0.732    | 31.6  | 1891.9
*-------------------+----------*-------*-------*
 Memory (MB)        | 300.0    | 235.3 | 104.9
*-------------------+----------*-------*-------*

  []

  IWPT2003 とそれを再現したrinkモジュールの SVMsはほぼ同等の精度を達成しています。
  学習ツール、品詞タグ付け器、および精度評価ツールが若干異なることを考慮すれば、IWPT2003の解析を再現できている思われます。
  解析速度は2次の多項式カーネルを使った場合で少なくとも 十倍程度は高速化できてきます。
  より高速にするにはLinear Kernelを使ったモデルが考えられますが、今回の最良素性では学習に３日以上かかること、また解析速度も２倍程度しか速くならないことが事前調査でわかっています。
  実装をもう少し工夫すること後述するMIRAと同程度には高速化可能と思われますが、学習時間がかかるため今回は比較の対象から除外しています。

  一方学習方法をMIRAに変えた場合、学習時間(SVMが約1日に対してMIRAは数時間)および解析速度も高速化できますが、当然精度は落ちます。
  ただし最近の先行研究{{Zhang & Nivre ACL11}}ではMIRAのような線形分類器とビームサーチを組み合わせて非常に高い精度(UAS で 0.926)に達しています。
  解析速度も 2GHz のCPUで 29 [sent./sec] 程度と記載されています。

今後の予定

  先行研究 Zhang & Nivre ACL2011 にあるように、ビームサーチを使うことで精度を上げることが可能なので、同様の機能をrinkモジュールにも取り込みたいと考えています。

  2013/3末にリリース予定の version 1.0　では以下の機能変更を予定しています。

    * SVM 学習機能の無効化（研究比較用のためモデルのロード、解析機能は可能のままにします。）

    * MIRA による学習機能、解析機能の正式対応

    * ビームサーチによる冗長解析機能（精度性能調査結果次第では無効または非推奨機能にする場合もあります）

  また品質向上のため可能な限り多くのテストを追加する予定です。
  (現状のテスト状況については{{{./project-reports.html}プロジェクトレポート}}をご参照ください。)

謝辞

  rink プロジェクトは{{{http://lr-www.pi.titech.ac.jp/wp/}東京工業大学精密工学研究所 奥村・高村研究室}}で研究員として在職中に立ち上げたプロジェクトです。
  奥村先生、高村さんをはじめ、研究室の皆さんにはいろいろとお世話になりました。この場をかりまして心より感謝いたします。

  本当にありがとうございました。

参考文献、リンク

  * {Y & M IWPT03}: {{{http://cl.aist-nara.ac.jp/papers/2003/hiroya-y/IWPT-2003.pdf}Hiroyasu Yamada and Yuji Matsumoto, "Statistical Dependency Analysis with Support Vector Machines", IWPT2003}}

  * {CoNLL-X}: {{{http://www.clips.ua.ac.be/conll2006/proceedings.html}The Tenth Conference on Natural Language Learning (CoNLL-X) 2006}}

  * {Penn2Malt} : {{http://w3.msi.vxu.se/~nivre/research/Penn2Malt.html}}

  * {pennconverter} : {{http://nlp.cs.lth.se/software/treebank_converter/}}

  * {mxpost}:　{{ftp://ftp.cis.upenn.edu/pub/adwait/jmx/}}

  * {Nakagawa ACL02} : {{{http://acl.ldc.upenn.edu/P/P02/P02-1063.pdf} Tetsuji Nakagawa and Taku Kudo and Yuji Matsumoto, "Revision Learning and its Application to Part-of-Speech Tagging", ACL2002}}

  * {Ratnaparkhi EMNLP96}: {{{http://www.inf.ed.ac.uk/resources/nlp/local_doc/mxpost_doc.pdf}Adwait Ratnaparkhi, "A Maximum Entropy Model for Part-of-Speech Tagging", EMNLP1996}}

  * {Zhang & Nivre ACL11}: {{{http://aclweb.org/anthology-new/P/P11/P11-2033.pdf} Yue Zhang and Joakim Nivre, "Transition-based Dependency Parsing with Rich Non-local Features", ACL2011 }}
