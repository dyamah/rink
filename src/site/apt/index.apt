
概要

  rink プロジェクトはIWPT2003で提案した英語の決定性上昇型依存構造解析({{{http://cl.aist-nara.ac.jp/papers/2003/hiroya-y/IWPT-2003.pdf} Yamada & Matsumoto IWPT03}})のJava実装です。

動作環境

  *JRE 1.6以降

  *libsvm.jar   (version 3.1) SVMライブラリ。SVMで学習をする場合に必要

  *commons-cli.jar  (version 1.2) コマンドライン解析ライブラリ

入出力データ形式

   解析対象文の入出力データは、{{{http://www.clips.ua.ac.be/conll2006/proceedings.html}CoNLL-X}} の{{{http://ilk.uvt.nl/conll/index.html#dataformat}書式}}と同じとします。

コーパスについて

  研究でよく利用する英語の依存構造コーパスは、Penn Treebank コーパスの句構造を依存構造に変換して使用します。
  ここでは公開されている。

  [[1]] Penn2Malt : {{http://w3.msi.vxu.se/~nivre/research/Penn2Malt.html}}

        Nivre のJava実装です。現在開発はfixしており、過去の論文の結果を再現するためのツールという位置づけのようです。
        後継は下のpennconverterです。

  [[2]] pennconverter : {{http://nlp.cs.lth.se/software/treebank_converter/}}

        ここではPenn Treebank コーパスにDavid Vadasの{{{http://sydney.edu.au/engineering/it/~dvadas1/?Noun_Phrases} 名詞句タグ付けの修正パッチ}}
        をあてることを強く奨めています。

  [[3]] ptbconv {{http://www.jaist.ac.jp/~h-yamada/software/ptbconv-3.0.tar.gz}}

        10年前自分で作ったruby 実装のコンバーターです

  []

  ptbconv と Penn2Maltの出力する依存構造は同じ主辞規則を使えば同じです。
  Penn2Malt は -LRB- などの特殊な単語の表記を "(" や "\{" に正しく変換して出力しており、一方 ptbconv は PennTreebank のまま(-LRB-)を出力している点が異なりますが、
  依存構造は双方で完全に一致していることを確認しています。後述する事件では Penn2Malt と同じ出力のものを利用しています。

  一方 pennconverter は、標準の主辞規則が大きく異なります。したがって出力する依存木は ptbconvやPenn2Malt とは異なります。

使用方法

* 前提

  * $train.txt: CoNLL-X書式の依存構造解析済みテキスト

  * $model: 学習モデル。

  * $test.txt:　CoNLL-X書式のテストデータ

  * $rink.jar: rinkモジュールjarファイル。使用しているバージョンに読み替えてください。

  * $libsvm.jar: libsvm のjar ファイル。　使用しているバージョンに読み替えてください。

  * $commons-cli.jar: コマンドラインパーザのjar ファイル。使用しているバージョンに読み替えてください。

* LIBSVMを利用した学習方法

  IWPT2003 と同じ設定で学習モデルを作成

  * 学習アルゴリズム：SVM

  * Kernel 関数： 2次の多項式 Kernel

  * 素性：IWPT2003での最良結果と同等

  * 訓練データの分割：依存構造を構築するかどうかを判定する２つの単語のうち左の単語の品詞でグループ化

+------------------------------------------------------------------------------------------------------------------------------------------------+
% java -Xmx 1024m -cp $rink.jar:$libsvm.jar:$commons-cli.jar jp.gr.java_conf.dyama.rink.tools.DependencyLearner -i $train.txt -o $model -l IWPT2003
+------------------------------------------------------------------------------------------------------------------------------------------------+

* 学習したモデルを利用した解析方法

+------------------------------------------------------------------------------------------------------------------------------------------------+
% java -Xmx 512m -cp $rink.jar:$commons-cli.jar jp.gr.java_conf.dyama.rink.tools.DependencyParser -i $test.txt -m $model -v
+------------------------------------------------------------------------------------------------------------------------------------------------+

  上記コマンドで標準出力にCoNLL-X形式の解析結果を出力します。
  また標準エラー出力に実行時間や使用メモリについての情報が出力されます。

+------------------------------------------------------------------------------------------------------------------------------------------------+
loading time[s]       :	1.42
parsing time[s]       :	77.12
parsing speed[sent/s] :	31.3
Total Time [s]    :	78.57
Total Memory [MB] :	237.71
+------------------------------------------------------------------------------------------------------------------------------------------------+

性能調査

* 実験環境

  * CPU: 2.3Ghz Intel Core i7

  * RAM: 16GB 1600MHz DDR3

  * OS: Mac OS X 10.8.2

  * JRE: 1.7

+---------------------------------------------------------------+
#以下は java -version の結果
java version "1.7.0_09"
Java(TM) SE Runtime Environment (build 1.7.0_09-b05)
Java HotSpot(TM) 64-Bit Server VM (build 23.5-b02, mixed mode)
+---------------------------------------------------------------+

* データ

  Penn Treebank の標準データセット(訓練データ section 02 から 21、テストデータ section 23)を使用しました。
  品詞タグ付けは先行研究でもよく利用されている {{{http://www.inf.ed.ac.uk/resources/nlp/local_doc/mxpost_doc.pdf} Adwait Ratnaparkhi EMNLP1996}}の実装{{{ftp://ftp.cis.upenn.edu/pub/adwait/jmx/} mxpost}}を利用。
  品詞タグ付けのモデルはmxpostに添付されていた標準のモデルを使用しました。

* 性能評価指標



  [[1]] POS Accuracy: 品詞タグ付けの精度

  [[2]] Dependency Accuracy: Punctuation 以外の単語に対する依存木の親の正解率

  [[3]] Unlabeled Attachment Score (UAS): CoNLL-Xの精度評価ツール {{{http://ilk.uvt.nl/conll/software.html#eval} eval.pl}} にて算出したDependency Accuracy 相当のスコア

  [[3]] Complete rate: Punctuation 以外の単語について１文で親ノードがすべて正しかった文の比率。

  [[4]] Root Accuracy: 依存木の親の正解数

  [[5]] Speed : 1秒あたりの解析文数（CoNLL-X書式の入出力も含む）

  [[6]] Memory: 実行時のピークヒープメモリサイズ (MB)

  []

  今回 Punctuation はテストデータの正解品詞により、以下の4品詞のいずれかがタグ付された単語をPunctuationとしています。
  "," ".", ":", "''", "``"

  これは IWPT2003 投稿時と若干異なります。(IWPT2003 では単語の表記が上記に該当するものをPunctuation
  CoNLL-Xのpunctuation は perl のunicode で定義されているものを用いているようだ
  　

* 結果：解析精度/速度/使用メモリ

  ここでは以下３つのモデルについて記載します。

  [[1]] IWPT2003: IWPT2003 に記載した精度。当時の実装を完全にビルドできていないので学習ツール、測定環境等は他２つとは異なります。
        また使用している品詞タグ付け器や精度評価ツールも若干異なっているので、あくまで参考情報という位置づけです。
        (当時の測定環境は CPU: Pentium 3.0Ghz, OSはLinux)

  [[2]] SVM: rink モジュールでIWPT2003最良モデルを再現したモデル。

  [[3]] MIRA: rinkモジュールに試験実装したMIRAによるモデル(SVMの代わりにMIRAによって解析アクションを学習、分類したもの）。素性はSVMと同一で 解析アクションを少しだけ拡張しています。

*-------------------+----------*-------*-------*
                    | IWPT2003 | SVM   | MIRA
*-------------------+----------*-------*-------*
 POS Accuracy       | 0.971    | 0.968 | 0.968
*-------------------+----------*-------*-------*
 Dependency Accuracy| 0.903    | 0.896 | 0.840
*-------------------+----------*-------*-------*
 UAS                | ?????    | 0.896 | 0.839
*-------------------+----------*-------*-------*
 Complete rate      | 0.384    | 0.375 | 0.236
*-------------------+----------*-------*-------*
 Root Accuracy      | 0.916    | 0.910 | 0.815
*-------------------+----------*-------*-------*
 Speed (sent./s)    |  1.3     | 31.6  | 1891.9
*-------------------+----------*-------*-------*
 Memory (MB)        | ?????    | 235.3 | 104.9
*-------------------+----------*-------*-------*

  []

  IWPT2003 とそれを再現したrinkモジュールの SVMは、ほぼ同等の精度を達成しています。
  学習ツール、品詞タグ付け器、および精度評価ツールが若干異なることを考慮すれば、IWPT2003の解析を再現できている思われます。
  解析速度は2次の多項式カーネルを使った場合で少なくとも 20 倍程度は高速化できてきます。(当時が遅すぎたという話もありますが）
  より高速にするにはLinear Kernelを使ったモデルが考えられますが、今回の最良素性では学習に３日以上かかること、また解析速度も２倍は速くはやくはならないことが事前調査でわかっています。

  よって実用的には{{{http://www.csie.ntu.edu.tw/~cjlin/liblinear/} liblinear}} などのライブラリを使うか、試験実装にしている MIRAのようなアルゴリズムを使う必要があります。

  また最近の研究では線形分類器とビームサーチを組み合わせて非常に高い精度を達しています。

  MaltPaserは　依存構造の

今後の予定

  SVMは



*謝辞


参考文献

  [[]]  http://aclweb.org/anthology-new/J/J11/J11-1007.pdf
